{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "print(f\"Memoria disponible: {psutil.virtual_memory().available / 1e9} GB\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, SimpleRNN, GRU, BatchNormalization\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYkk3aO24hxQ",
        "outputId": "b04f899f-6713-4728-b86b-0983e63ef1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria disponible: 12.35503104 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos\n",
        "# data = pd.read_csv(\"Datos_ConT.csv\")\n",
        "data = pd.read_csv(\"Datos_Con2HResampled.csv\")\n",
        "data = data.rename(columns={'DateTime_': 'Fecha'})\n",
        "data['Fecha'] = pd.to_datetime(data['Fecha'])\n"
      ],
      "metadata": {
        "id": "bWo2nv6O4j1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover columna 'Magnitud'\n",
        "magnitud_column = data['Magnitud']\n",
        "data = data.drop('Magnitud', axis=1)\n",
        "data.insert(0, 'Magnitud', magnitud_column)"
      ],
      "metadata": {
        "id": "8wZR7uYe4lem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data.drop(columns=['Fecha']))"
      ],
      "metadata": {
        "id": "c_SgxoZw40ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear secuencias\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length, :])\n",
        "        y.append(data[i+seq_length, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 48\n",
        "X, y = create_sequences(data_scaled, seq_length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "n_features = data.shape[1] - 1\n",
        "l2_reg = l2(0.01)"
      ],
      "metadata": {
        "id": "TbU7hEa3443i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo LSTM\n",
        "model_lstm = Sequential([\n",
        "    Bidirectional(LSTM(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg), input_shape=(seq_length, n_features)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(50, activation='tanh', kernel_regularizer=l2_reg)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Modelos RNN y GRU\n",
        "model_rnn = Sequential([\n",
        "    SimpleRNN(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg, input_shape=(seq_length, n_features)),\n",
        "    Dropout(0.3),\n",
        "    SimpleRNN(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg),\n",
        "    Dropout(0.3),\n",
        "    SimpleRNN(50, activation='tanh', kernel_regularizer=l2_reg),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model_gru = Sequential([\n",
        "    GRU(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg, input_shape=(seq_length, n_features)),\n",
        "    Dropout(0.3),\n",
        "    GRU(50, return_sequences=True, activation='tanh', kernel_regularizer=l2_reg),\n",
        "    Dropout(0.3),\n",
        "    GRU(50, activation='tanh', kernel_regularizer=l2_reg),\n",
        "    Dropout(0.3),\n",
        "    Dense(1)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpLpYzXu4_U2",
        "outputId": "95240b68-1920-48f4-eb9a-2479b855ef29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar modelos\n",
        "for model, name in [(model_lstm, \"LSTM\"), (model_rnn, \"RNN\"), (model_gru, \"GRU\")]:\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    print(f\"Entrenando modelo {name}...\")\n",
        "    model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeRayiml5Bil",
        "outputId": "96c98592-c581-4462-92c2-3fc8a1bdad04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando modelo LSTM...\n",
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 347ms/step - loss: 3.3717 - mae: 0.0107 - val_loss: 0.3265 - val_mae: 0.1600\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 325ms/step - loss: 0.1349 - mae: 0.0092 - val_loss: 0.1248 - val_mae: 0.2015\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 333ms/step - loss: 0.0034 - mae: 0.0084 - val_loss: 0.1194 - val_mae: 0.2024\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 341ms/step - loss: 0.0015 - mae: 0.0089 - val_loss: 0.1189 - val_mae: 0.2027\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 343ms/step - loss: 0.0017 - mae: 0.0098 - val_loss: 0.1188 - val_mae: 0.2028\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 324ms/step - loss: 0.0016 - mae: 0.0100 - val_loss: 0.1203 - val_mae: 0.2017\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 322ms/step - loss: 0.0015 - mae: 0.0085 - val_loss: 0.1198 - val_mae: 0.2021\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 335ms/step - loss: 0.0017 - mae: 0.0096 - val_loss: 0.1202 - val_mae: 0.2018\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 322ms/step - loss: 0.0015 - mae: 0.0087 - val_loss: 0.1216 - val_mae: 0.2008\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 324ms/step - loss: 0.0017 - mae: 0.0095 - val_loss: 0.1222 - val_mae: 0.2003\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 327ms/step - loss: 0.0015 - mae: 0.0082 - val_loss: 0.1186 - val_mae: 0.2030\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 324ms/step - loss: 0.0014 - mae: 0.0084 - val_loss: 0.1206 - val_mae: 0.2015\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 335ms/step - loss: 0.0014 - mae: 0.0076 - val_loss: 0.1198 - val_mae: 0.2021\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 325ms/step - loss: 0.0013 - mae: 0.0076 - val_loss: 0.1202 - val_mae: 0.2018\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 337ms/step - loss: 0.0014 - mae: 0.0079 - val_loss: 0.1199 - val_mae: 0.2021\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 345ms/step - loss: 0.0013 - mae: 0.0078 - val_loss: 0.1209 - val_mae: 0.2013\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 339ms/step - loss: 0.0015 - mae: 0.0081 - val_loss: 0.1214 - val_mae: 0.2009\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 322ms/step - loss: 0.0015 - mae: 0.0078 - val_loss: 0.1202 - val_mae: 0.2018\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 342ms/step - loss: 0.0014 - mae: 0.0083 - val_loss: 0.1208 - val_mae: 0.2014\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 324ms/step - loss: 0.0017 - mae: 0.0091 - val_loss: 0.1203 - val_mae: 0.2017\n",
            "Entrenando modelo RNN...\n",
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - loss: 1.1295 - mae: 0.1904 - val_loss: 0.6756 - val_mae: 0.2171\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 0.4405 - mae: 0.0370 - val_loss: 0.2962 - val_mae: 0.1975\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - loss: 0.1414 - mae: 0.0136 - val_loss: 0.1625 - val_mae: 0.1953\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 0.0401 - mae: 0.0096 - val_loss: 0.1286 - val_mae: 0.1972\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - loss: 0.0114 - mae: 0.0072 - val_loss: 0.1198 - val_mae: 0.2002\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - loss: 0.0044 - mae: 0.0087 - val_loss: 0.1193 - val_mae: 0.2016\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - loss: 0.0023 - mae: 0.0084 - val_loss: 0.1186 - val_mae: 0.2029\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 0.0020 - mae: 0.0096 - val_loss: 0.1204 - val_mae: 0.2017\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 0.0016 - mae: 0.0086 - val_loss: 0.1195 - val_mae: 0.2024\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 0.0016 - mae: 0.0094 - val_loss: 0.1208 - val_mae: 0.2014\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 0.0016 - mae: 0.0091 - val_loss: 0.1203 - val_mae: 0.2018\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - loss: 0.0014 - mae: 0.0080 - val_loss: 0.1201 - val_mae: 0.2019\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - loss: 0.0014 - mae: 0.0086 - val_loss: 0.1206 - val_mae: 0.2015\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 0.0015 - mae: 0.0083 - val_loss: 0.1200 - val_mae: 0.2020\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 0.0014 - mae: 0.0089 - val_loss: 0.1194 - val_mae: 0.2024\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - loss: 0.0016 - mae: 0.0097 - val_loss: 0.1212 - val_mae: 0.2011\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 0.0017 - mae: 0.0098 - val_loss: 0.1207 - val_mae: 0.2015\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 0.0017 - mae: 0.0096 - val_loss: 0.1210 - val_mae: 0.2012\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 0.0017 - mae: 0.0091 - val_loss: 0.1207 - val_mae: 0.2015\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 0.0014 - mae: 0.0085 - val_loss: 0.1199 - val_mae: 0.2020\n",
            "Entrenando modelo GRU...\n",
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - loss: 1.0665 - mae: 0.0118 - val_loss: 0.2669 - val_mae: 0.1971\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 159ms/step - loss: 0.0885 - mae: 0.0094 - val_loss: 0.1280 - val_mae: 0.2011\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0053 - mae: 0.0086 - val_loss: 0.1211 - val_mae: 0.2013\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - loss: 0.0015 - mae: 0.0085 - val_loss: 0.1208 - val_mae: 0.2014\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0017 - mae: 0.0094 - val_loss: 0.1216 - val_mae: 0.2008\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - loss: 0.0015 - mae: 0.0083 - val_loss: 0.1184 - val_mae: 0.2032\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0016 - mae: 0.0097 - val_loss: 0.1199 - val_mae: 0.2020\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 157ms/step - loss: 0.0015 - mae: 0.0086 - val_loss: 0.1199 - val_mae: 0.2020\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - loss: 0.0015 - mae: 0.0092 - val_loss: 0.1213 - val_mae: 0.2010\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 0.0014 - mae: 0.0080 - val_loss: 0.1195 - val_mae: 0.2024\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 157ms/step - loss: 0.0015 - mae: 0.0083 - val_loss: 0.1214 - val_mae: 0.2010\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 0.0018 - mae: 0.0095 - val_loss: 0.1202 - val_mae: 0.2018\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 0.0014 - mae: 0.0085 - val_loss: 0.1217 - val_mae: 0.2007\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - loss: 0.0014 - mae: 0.0080 - val_loss: 0.1209 - val_mae: 0.2013\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - loss: 0.0013 - mae: 0.0074 - val_loss: 0.1200 - val_mae: 0.2019\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 157ms/step - loss: 0.0014 - mae: 0.0079 - val_loss: 0.1204 - val_mae: 0.2016\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0017 - mae: 0.0099 - val_loss: 0.1212 - val_mae: 0.2011\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 0.0017 - mae: 0.0092 - val_loss: 0.1207 - val_mae: 0.2015\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.0016 - mae: 0.0088 - val_loss: 0.1225 - val_mae: 0.2011\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 0.0014 - mae: 0.0079 - val_loss: 0.1207 - val_mae: 0.2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar modelos\n",
        "for model, name in [(model_lstm, \"LSTM\"), (model_rnn, \"RNN\"), (model_gru, \"GRU\")]:\n",
        "    predictions = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    print(f\"Resultados para {name}:\")\n",
        "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdyTymjF5GSx",
        "outputId": "7605eba0-3cf8-4cac-f000-ad491798f3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step\n",
            "Resultados para LSTM:\n",
            "MAE: 0.2017, MSE: 0.1203, RMSE: 0.3469, R^2: -0.4654\n",
            "\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "Resultados para RNN:\n",
            "MAE: 0.2020, MSE: 0.1199, RMSE: 0.3463, R^2: -0.4607\n",
            "\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n",
            "Resultados para GRU:\n",
            "MAE: 0.2014, MSE: 0.1207, RMSE: 0.3475, R^2: -0.4703\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW87GFrS4d7v",
        "outputId": "076934e2-9a6d-4aa4-99fe-8473a1b79e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-a344f87c406f>:23: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  future_dates = pd.date_range(start=start_date, periods=days_to_predict, freq=\"2H\")\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "                 Fecha      LSTM       RNN       GRU\n",
            "0  2022-02-10 06:00:00  0.004642  0.003338  0.003991\n",
            "1  2022-02-10 08:00:00  0.004642  0.003338  0.003991\n",
            "2  2022-02-10 10:00:00  0.004642  0.003338  0.003991\n",
            "3  2022-02-10 12:00:00  0.004642  0.003338  0.003991\n",
            "4  2022-02-10 14:00:00  0.004642  0.003338  0.003991\n",
            "5  2022-02-10 16:00:00  0.004642  0.003338  0.003991\n",
            "6  2022-02-10 18:00:00  0.004642  0.003338  0.003991\n",
            "7  2022-02-10 20:00:00  0.004642  0.003338  0.003991\n",
            "8  2022-02-10 22:00:00  0.004642  0.003338  0.003991\n",
            "9  2022-02-11 00:00:00  0.004642  0.003338  0.003991\n",
            "10 2022-02-11 02:00:00  0.004642  0.003338  0.003991\n",
            "11 2022-02-11 04:00:00  0.004642  0.003338  0.003991\n"
          ]
        }
      ],
      "source": [
        "# Función para predicciones futuras\n",
        "def predict_for_dates(model, df, scaler, start_date, days_to_predict):\n",
        "    df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
        "    start_date = pd.to_datetime(start_date)\n",
        "    input_data = df[df['Fecha'] >= start_date].drop(columns=['Fecha']).values\n",
        "    input_scaled = scaler.transform(input_data)[-seq_length:]\n",
        "\n",
        "    predictions = []\n",
        "    current_input = np.array([input_scaled])\n",
        "\n",
        "    for _ in range(days_to_predict):\n",
        "        pred = model.predict(current_input)[0][0]\n",
        "        predictions.append(pred)\n",
        "        new_input = np.hstack([[pred], np.zeros(n_features - 1)])\n",
        "        current_input = np.roll(current_input, -1, axis=1)\n",
        "        current_input[0, -1, :] = new_input\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Predicción futura\n",
        "start_date = data['Fecha'].max()\n",
        "days_to_predict = 12\n",
        "future_dates = pd.date_range(start=start_date, periods=days_to_predict, freq=\"2H\")\n",
        "\n",
        "future_predictions_lstm = predict_for_dates(model_lstm, data, scaler, start_date, days_to_predict)\n",
        "future_predictions_rnn = predict_for_dates(model_rnn, data, scaler, start_date, days_to_predict)\n",
        "future_predictions_gru = predict_for_dates(model_gru, data, scaler, start_date, days_to_predict)\n",
        "\n",
        "predictions_df = pd.DataFrame({\n",
        "    \"Fecha\": future_dates,\n",
        "    \"LSTM\": future_predictions_lstm,\n",
        "    \"RNN\": future_predictions_rnn,\n",
        "    \"GRU\": future_predictions_gru\n",
        "})\n",
        "\n",
        "print(predictions_df)"
      ]
    }
  ]
}